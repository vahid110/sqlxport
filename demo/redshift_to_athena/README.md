# Redshift UNLOAD â†’ Glue â†’ Athena Demo

This demo shows how to export data from **Amazon Redshift** to **Amazon S3** using the `UNLOAD` command, generate a Glue-compatible table definition with `sqlxport`, register it in the **AWS Glue Catalog**, and validate with **Amazon Athena**.

## ğŸš€ Quick Start

```bash
./run_sqlxport.sh <s3-bucket> <aws-region>
```

## ğŸ“¦ What It Does

1. Bootstraps a Redshift table (`logs`) with sample data.
2. Runs `UNLOAD` to export the table to S3 in Parquet format.
3. Downloads a sample `.parquet` file locally.
4. Generates Athena-compatible `CREATE EXTERNAL TABLE` DDL.
5. Registers the Glue table via Athena.
6. Repairs partitions (if needed).
7. Validates visibility with an Athena `COUNT(*)` query.

## ğŸ“‚ Folder Contents

```
redshift_to_athena/
â”œâ”€â”€ run_sqlxport.sh        # Full automation script
â”œâ”€â”€ glue_table.sql         # Generated DDL (auto-overwritten)
â”œâ”€â”€ tmp_unload/            # Temporary folder with downloaded .parquet
â””â”€â”€ preview_redshift_unload.ipynb  # Optional Jupyter preview
```

## ğŸ§ª Requirements

- A Redshift cluster with UNLOAD permissions.
- A valid IAM role for S3 access.
- AWS CLI configured
- Python + `sqlxport` installed
- Jupyter (optional for preview)

## ğŸ“ Notes

- IAM role and Redshift DB URL must be provided via environment variables:
  - `REDSHIFT_DB_URL`
  - `REDSHIFT_IAM_ROLE`
- The script cleans previous outputs each time you run it.
- It works with the real Redshift, not a mock or containerized DB.

## ğŸ“Š Sample Athena Query Used for Validation

```sql
SELECT COUNT(*) FROM logs_unload;
```

## ğŸ™Œ Credits

Made with â¤ï¸ using `sqlxport`, AWS Redshift, Glue, and Athena.
